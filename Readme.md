<marquee behavior="scroll" direction="left">ğŸš€ **Há»‡ Thá»‘ng PhÃ¡t Hiá»‡n & Theo DÃµi Váº­t Thá»ƒ** ğŸš€</marquee>

> **LANGUAGE SWITCH**: Click on the language you prefer:
> <a href="#-há»‡-thá»‘ng-phÃ¡t-hiá»‡n--theo-dÃµi-váº­t-thá»ƒ">ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t</a> | 
> <a href="#-english-version-">ğŸ‡¬ğŸ‡§ English</a>


# ğŸ“– Há»‡ Thá»‘ng PhÃ¡t Hiá»‡n & Theo DÃµi Váº­t Thá»ƒ

> **MÃ´ táº£**: ÄÃ¢y lÃ  má»™t bá»™ pipeline bao gá»“m nhiá»u module, sá»­ dá»¥ng YOLO, GStreamer vá»›i Hailo, Sort tracker vÃ  giao tiáº¿p Ä‘áº¿n STM32 Ä‘á»ƒ phÃ¡t hiá»‡n, theo dÃµi vÃ  Ä‘iá»u khiá»ƒn hÆ°á»›ng di chuyá»ƒn dá»±a trÃªn camera vÃ  cáº£m biáº¿n.

---

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)  
- [YÃªu cáº§u há»‡ thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)  
- [CÃ i Ä‘áº·t & Khá»Ÿi cháº¡y](#-cÃ i-Ä‘áº·t--khá»Ÿi-cháº¡y)  
- [Kiáº¿n trÃºc tá»•ng quan](#-kiáº¿n-trÃºc-tá»•ng-quan)  
- [Flowchart há»‡ thá»‘ng](#-flowchart-há»‡-thá»‘ng)  
- [Chi tiáº¿t tá»«ng module](#-chi-tiáº¿t-tá»«ng-module)  
  - [1. main_2cls.py](#1-main_2clspy)  
  - [2. basic_pipelines/detection.py](#2-basic_pipelinesdetectionpy)  
  - [3. basic_pipelines/instance_segmentation.py](#3-basic_pipelinesinstance_segmentationpy)  
- [Kiá»ƒm thá»­](#-kiá»ƒm-thá»­)  
- [Ghi chÃº & Lá»i nháº¯c](#-ghi-chÃº--lá»i-nháº¯c)  

---

## ğŸ” Giá»›i thiá»‡u
Há»‡ thá»‘ng gá»“m:
- **PhÃ¡t hiá»‡n 2 lá»›p** (basket, backboard) vá»›i YOLO engine (TensorRT).  
- **Theo dÃµi** báº±ng Sort tracker.  
- **Pipeline GStreamer** sá»­ dá»¥ng Hailo-RPI cho phÃ¡t hiá»‡n vÃ  phÃ¢n Ä‘oáº¡n.  
- **Giao tiáº¿p STM32**: gá»­i offset & direction qua UART.  

---

## ğŸ–¥ YÃªu cáº§u há»‡ thá»‘ng
- OS: Linux (Raspberry Pi OS) hoáº·c Windows.  
- Python â‰¥ 3.7  
- OpenCV, ultralytics, numpy, hailo-apps-infra, GStreamer.  
- STM32 (UART), module lidar (tÃ¹y chá»n).  

---

## âš™ï¸ CÃ i Ä‘áº·t & Khá»Ÿi cháº¡y
```bash
# CÃ i dependencies
pip install -r requirements.txt
# Cháº¡y YOLO pipeline chÃ­nh
python main_2cls.py
# Cháº¡y GStreamer detection
python basic_pipelines/detection.py --input video.mp4
# Cháº¡y GStreamer instance segmentation
python basic_pipelines/instance_segmentation.py --input video.mp4
```

---

## ğŸ— Kiáº¿n trÃºc tá»•ng quan
```mermaid
flowchart LR
  A[Camera/Cá»¥m video] -->|Frame| B[Preprocessing & Resize]
  B --> C[YOLO Detection main_2cls]
  C --> D[Filter & Sort Tracker]
  D --> E[Calculator Offset & Direction]
  E --> F[Gá»­i UART â†’ STM32]
  C --> G[Visualization: váº½ bounding box, FPS]
  
  subgraph GStreamer_Pipelines
    H[basic_pipelines/detection.py] --> I[Hailo Detection]
    I --> J[Process detections no-track]
    J --> K[Visualize & gá»­i STM32]
    L[basic_pipelines/instance_segmentation.py] --> M[Hailo Instance Segmentation]
    M --> N[Overlay mask lÃªn frame]
  end
```

---

## ğŸ—‚ Chi tiáº¿t tá»«ng module

<details>
<summary>1. main_2cls.py</summary>

- Sá»­ dá»¥ng `ultralytics.YOLO` Ä‘á»ƒ load engine TensorRT 2 lá»›p.  
- DÃ² tÃ¬m bounding box, confidence, phÃ¢n biá»‡t basket/backboard.  
- DÃ¹ng `cover.sort.Sort` Ä‘á»ƒ track object.  
- TÃ­nh offset vá»›i `calculator_offset_stm32()`, xÃ¡c Ä‘á»‹nh direction vá»›i `auto_drive()`.  
- Gá»­i dá»¯ liá»‡u xuá»‘ng STM32 qua hÃ m `create_stm32_message_1()` trong `cover.utils`.  
- Hiá»ƒn thá»‹ káº¿t quáº£ trá»±c tiáº¿p (rectangle, FPS).  
</details>

<details>
<summary>2. basic_pipelines/detection.py</summary>

- Dá»±a trÃªn GStreamer + Hailo RPI.  
- Nháº­n buffer, parse ROI â†’ Hailo detections.  
- Chuyá»ƒn thÃ nh format `(x1,y1,x2,y2,conf,class_id)`.  
- Xá»­ lÃ½ báº±ng `process_detections_no_track()`.  
- Visualize tÆ°Æ¡ng tá»±, tÃ­nh offset & direction.  
- (TÃ¹y chá»n) Gá»­i UART xuá»‘ng STM32.  
- Quáº£n lÃ½ FPS, chuyá»ƒn frame sang BGR Ä‘á»ƒ hiá»ƒn thá»‹.  
</details>

<details>
<summary>3. basic_pipelines/instance_segmentation.py</summary>

- GStreamer Instance Segmentation App.  
- Skip frame Ä‘á»ƒ giáº£m táº£i.  
- DÃ¹ng Hailo Ä‘á»ƒ detect `person` + unique ID.  
- Láº¥y mask, reshape, overlay mÃ u theo track_id.  
- In thÃ´ng tin ID, label, confidence lÃªn console.  
</details>

---

## âœ… Kiá»ƒm thá»­

Táº­p script `tests/test_edge_cases.py` kiá»ƒm:
- ÄÆ°á»ng dáº«n video khÃ´ng tá»“n táº¡i.  
- Äá»‹nh dáº¡ng file khÃ´ng há»— trá»£.  
- Tham sá»‘ dÃ²ng lá»‡nh khÃ´ng há»£p lá»‡.  

```bash
pytest tests/test_edge_cases.py
```

---

## ğŸ“ Ghi chÃº & Lá»i nháº¯c

- ThÃ´ng tin cáº¥u hÃ¬nh STM32: `cover/utils.py` & `cover/send_uart.py`.  
- Äiá»u chá»‰nh ngÆ°á»¡ng tin cáº­y (`conf > 0.5`).  
- CÃ³ thá»ƒ bá»• sung module lidar Ä‘á»ƒ láº¥y khoáº£ng cÃ¡ch thá»±c.  
- Äá»ƒ má»Ÿ rá»™ng thÃªm class detection, rebuild engine YOLO tÆ°Æ¡ng á»©ng.  

> **TIP**: Náº¿u muá»‘n xem minh há»a Ä‘á»™ng, cÃ³ thá»ƒ thÃªm file GIF vÃ o `docs/pipeline_animation.gif` vÃ  nhÃºng:
> ```markdown
> ![Pipeline Animation](docs/pipeline_animation.gif)
> ```

---

# ğŸŒ English Version ğŸŒ

<marquee behavior="scroll" direction="left">ğŸš€ **Object Detection & Tracking System** ğŸš€</marquee>

# ğŸ“– Object Detection & Tracking System

> **Description**: This is a pipeline system comprising multiple modules, using YOLO, GStreamer with Hailo, Sort tracker, and STM32 communication to detect, track, and control movement direction based on camera and sensors.

---

## ğŸ“‹ Table of Contents

- [Introduction](#-introduction)  
- [System Requirements](#-system-requirements)  
- [Installation & Running](#-installation--running)  
- [System Architecture](#-system-architecture)  
- [System Flowchart](#-system-flowchart)  
- [Module Details](#-module-details)  
  - [1. main_2cls.py](#1-main_2clspy-1)  
  - [2. basic_pipelines/detection.py](#2-basic_pipelinesdetectionpy-1)  
  - [3. basic_pipelines/instance_segmentation.py](#3-basic_pipelinesinstance_segmentationpy-1)  
- [Testing](#-testing)  
- [Notes & Reminders](#-notes--reminders)  

---

## ğŸ” Introduction
The system includes:
- **Two-class detection** (basket, backboard) with YOLO engine (TensorRT).  
- **Tracking** using Sort tracker.  
- **GStreamer pipeline** using Hailo-RPI for detection and segmentation.  
- **STM32 communication**: sending offset & direction via UART.  

---

## ğŸ–¥ System Requirements
- OS: Linux (Raspberry Pi OS) or Windows.  
- Python â‰¥ 3.7  
- OpenCV, ultralytics, numpy, hailo-apps-infra, GStreamer.  
- STM32 (UART), lidar module (optional).  

---

## âš™ï¸ Installation & Running
```bash
# Install dependencies
pip install -r requirements.txt
# Run main YOLO pipeline
python main_2cls.py
# Run GStreamer detection
python basic_pipelines/detection.py --input video.mp4
# Run GStreamer instance segmentation
python basic_pipelines/instance_segmentation.py --input video.mp4
```

---

## ğŸ— System Architecture
```mermaid
flowchart LR
  A[Camera/Video source] -->|Frame| B[Preprocessing & Resize]
  B --> C[YOLO Detection main_2cls]
  C --> D[Filter & Sort Tracker]
  D --> E[Calculator Offset & Direction]
  E --> F[Send UART â†’ STM32]
  C --> G[Visualization: draw bounding box, FPS]
  
  subgraph GStreamer_Pipelines
    H[basic_pipelines/detection.py] --> I[Hailo Detection]
    I --> J[Process detections no-track]
    J --> K[Visualize & send to STM32]
    L[basic_pipelines/instance_segmentation.py] --> M[Hailo Instance Segmentation]
    M --> N[Overlay mask on frame]
  end
```

---

## ğŸ—‚ Module Details

<details>
<summary>1. main_2cls.py</summary>

- Uses `ultralytics.YOLO` to load TensorRT 2-class engine.  
- Detects bounding boxes, confidence, distinguishes basket/backboard.  
- Uses `cover.sort.Sort` for object tracking.  
- Calculates offset with `calculator_offset_stm32()`, determines direction with `auto_drive()`.  
- Sends data to STM32 via `create_stm32_message_1()` function in `cover.utils`.  
- Displays results directly (rectangle, FPS).  
</details>

<details>
<summary>2. basic_pipelines/detection.py</summary>

- Based on GStreamer + Hailo RPI.  
- Receives buffer, parses ROI â†’ Hailo detections.  
- Converts to format `(x1,y1,x2,y2,conf,class_id)`.  
- Processes using `process_detections_no_track()`.  
- Similar visualization, calculates offset & direction.  
- (Optional) Sends UART to STM32.  
- Manages FPS, converts frame to BGR for display.  
</details>

<details>
<summary>3. basic_pipelines/instance_segmentation.py</summary>

- GStreamer Instance Segmentation App.  
- Skips frames to reduce computational load.  
- Uses Hailo to detect `person` + unique ID.  
- Gets mask, reshapes, overlays color according to track_id.  
- Prints ID, label, confidence information to console.  
</details>

---

## âœ… Testing

The `tests/test_edge_cases.py` script tests:
- Non-existent video paths.  
- Unsupported file formats.  
- Invalid command-line parameters.  

```bash
pytest tests/test_edge_cases.py
```

---

## ğŸ“ Notes & Reminders

- STM32 configuration info: `cover/utils.py` & `cover/send_uart.py`.  
- Adjust confidence threshold (`conf > 0.5`).  
- Can add lidar module to get actual distance.  
- To extend with more detection classes, rebuild corresponding YOLO engine.  

> **TIP**: If you want to see dynamic illustrations, you can add a GIF file to `docs/pipeline_animation.gif` and embed it:
> ```markdown
> ![Pipeline Animation](docs/pipeline_animation.gif)
> ```

